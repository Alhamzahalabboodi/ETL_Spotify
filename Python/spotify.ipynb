{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c9795d2-8087-4549-a86e-dfeaf79c585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from pprint import pprint\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from config import spotify_client_id,spotify_client_secret,spotify_redirect_url,db_username,db_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeeb3c4d-2422-436d-b4b1-09ba01448933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Python file to extract the songs from Spotify, transform the data and then load it into PostgreSQL.\n",
    "# It is placed into a function for my Airflow DAG to call\n",
    "def spotify_etl_func():\n",
    "    # Step one: extract:\n",
    "    spotify_client_id=spotify_client_id\n",
    "    spotify_client_secret=spotify_client_secret\n",
    "    spotify_redirect_url=spotify_redirect_url\n",
    "\n",
    "    sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=spotify_client_id,\n",
    "                                                   client_secret=spotify_client_secret,\n",
    "                                                   redirect_uri=spotify_redirect_url,\n",
    "                                                   scope=\"user-read-recently-played\"))\n",
    "    recently_played = sp.current_user_recently_played(limit=50)\n",
    "    \n",
    "    #if the length of recently_played is 0 for some reason just exit the program\n",
    "    if len(recently_played) ==0:\n",
    "        sys.exit(\"No results recieved from Spotify\")\n",
    "    # Step 2: Transform    \n",
    "    #Creating the Album Data Structure:\n",
    "    album_list = []\n",
    "    for row in recently_played['items']:\n",
    "        album_id = row['track']['album']['id']\n",
    "        album_name = row['track']['album']['name']\n",
    "        album_release_date = row['track']['album']['release_date']\n",
    "        album_total_tracks = row['track']['album']['total_tracks']\n",
    "        album_url = row['track']['album']['external_urls']['spotify']\n",
    "        album_element = {'album_id':album_id,'album_name':album_name,'release_date':album_release_date,\n",
    "                        'total_tracks':album_total_tracks,'album_url':album_url}\n",
    "        album_list.append(album_element)\n",
    "        \n",
    "    #Creating the Artist Data Structure:\n",
    "    #As we can see here this is another way to store data with using a dictionary of lists. Personally, for this project\n",
    "    #I think using the strategy with the albums dicts(lists) is better. It allows for more functionality if we have to sort for example.\n",
    "    # Additionally we do not need to make the temporary lists. There may be a more pythonic method to creating this but it is not my preferred method\n",
    "    artist_dict = {}\n",
    "    id_list = []\n",
    "    name_list = []\n",
    "    url_list = []\n",
    "    for item in recently_played['items']:\n",
    "        for key,value in item.items():\n",
    "            if key == \"track\":\n",
    "                for data_point in value['artists']:\n",
    "                    id_list.append(data_point['id'])\n",
    "                    name_list.append(data_point['name'])\n",
    "                    url_list.append(data_point['external_urls']['spotify'])\n",
    "    artist_dict = {'artist_id':id_list,'artist_name':name_list,'artist_url':url_list}\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Creating the Track(Song) Data Structure:\n",
    "    song_list = []\n",
    "    for row in recently_played['items']:\n",
    "        song_id = row['track']['id']\n",
    "        song_name = row['track']['name']\n",
    "        song_duration = row['track']['duration_ms']\n",
    "        song_url = row['track']['external_urls']['spotify']\n",
    "        song_popularity = row['track']['popularity']\n",
    "        song_time_played = row['played_at']\n",
    "        album_id = row['track']['album']['id']\n",
    "        artist_id = row['track']['album']['artists'][0]['id']\n",
    "        song_element = {'song_id':song_id,'song_name':song_name,'duration_ms':song_duration,'song_url':song_url,\n",
    "                        'popularity':song_popularity,'date_time_played':song_time_played,'album_id':album_id,\n",
    "                        'artist_id':artist_id\n",
    "                       }\n",
    "        song_list.append(song_element)\n",
    "        \n",
    "        \n",
    "    #Now that we have these two lists and one dictionary ready lets convert them to DataFrames\n",
    "    #We will need to do some cleaning and add our Unique ID for the Track\n",
    "    #Then load into PostgresSQL from the dataframe\n",
    "\n",
    "    #Album = We can also just remove duplicates here. We dont want to load two of the same albums just to have SQL drop it later\n",
    "    album_df = pd.DataFrame.from_dict(album_list)\n",
    "    album_df = album_df.drop_duplicates(subset=['album_id'])\n",
    "\n",
    "    #Artist = We can also just remove duplicates here. We dont want to load two of the same artists just to have SQL drop it later\n",
    "    artist_df = pd.DataFrame.from_dict(artist_dict)\n",
    "    artist_df = artist_df.drop_duplicates(subset=['artist_id'])\n",
    "    \n",
    "    #Song Dataframe\n",
    "    song_df = pd.DataFrame.from_dict(song_list)\n",
    "    #date_time_played is an object (data type) changing to a timestamp\n",
    "    song_df['date_time_played'] = pd.to_datetime(song_df['date_time_played'])\n",
    "    #converting to my timezone of Central\n",
    "    song_df['date_time_played'] = song_df['date_time_played'].dt.tz_convert('US/Central')\n",
    "    #I have to remove the timezone part from the date/time/timezone.\n",
    "    song_df['date_time_played'] = song_df['date_time_played'].astype(str).str[:-7]\n",
    "    song_df['date_time_played'] = pd.to_datetime(song_df['date_time_played'])\n",
    "    #Creating a Unix Timestamp for Time Played. This will be one half of our unique identifier\n",
    "    song_df['UNIX_Time_Stamp'] = (song_df['date_time_played'] - pd.Timestamp(\"1970-01-01\"))//pd.Timedelta('1s')\n",
    "    # I need to create a new unique identifier column because we dont want to be insterting the same song played at the same song\n",
    "    # I can have the same song multiple times in my database but I dont want to have the same song played at the same time\n",
    "    song_df['unique_identifier'] = song_df['song_id'] + \"-\" + song_df['UNIX_Time_Stamp'].astype(str)\n",
    "    song_df = song_df[['unique_identifier','song_id','song_name','duration_ms','song_url','popularity','date_time_played','album_id','artist_id']]\n",
    "    song_df.to_csv(\"spotify_etl.csv\")\n",
    "\n",
    "    # Step 3: Load\n",
    "    # Create Engine\n",
    "    engine = sqlalchemy.create_engine(f\"postgresql://{db_username}:{db_password}@localhost/spotify_etl\")\n",
    "    # Load table 1\n",
    "    album_df.to_sql(\"spotify_albums\",engine, index=False, if_exists=\"append\")\n",
    "    # Load table 2\n",
    "    artist_df.to_sql(\"spotify_artists\",engine, index=False, if_exists=\"append\")\n",
    "    # Load Table 3\n",
    "    song_df.to_sql(\"spotify_tracks\",engine, index=False, if_exists=\"append\")\n",
    "    \n",
    "spotify_etl_func()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "772f71a7-06c6-4bd6-b2cb-5bbe85634a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Python file to extract the daily top 50 songs in the US from Spotify, transform the data and then load it into PostgreSQL.\n",
    "# It is placed into a function for my Airflow DAG to call\n",
    "\n",
    "def spotify_top50usa_func(creator, playlist_id):\n",
    "    \n",
    "    spotify_client_id=spotify_client_id\n",
    "    spotify_client_secret=spotify_client_secret\n",
    "    spotify_redirect_url=spotify_redirect_url\n",
    "    \n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=spotify_client_id, client_secret=spotify_client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)\n",
    "    \n",
    "    #step1 : create columns \n",
    "    playlist_features_list = [\"artist_name\",\"album_name\",\"song_name\",  \"song_id\",\"danceability\",\"energy\",\"key\",\"loudness\",\"mode\", \"speechiness\",\"instrumentalness\",\"liveness\",\"valence\",\"tempo\", \"duration_ms\",\"time_signature\"]\n",
    "    # Create a DataFrame that will hold the columns\n",
    "    playlist_df = pd.DataFrame(columns = playlist_features_list)\n",
    "    \n",
    "    #step2\n",
    "    \n",
    "    playlist = sp.user_playlist_tracks(creator, playlist_id, limit=50)[\"items\"]\n",
    "    for track in playlist:\n",
    "        # Create empty dict\n",
    "        playlist_features = {}\n",
    "        # Get metadata\n",
    "        playlist_features[\"artist_name\"] = track[\"track\"][\"album\"][\"artists\"][0][\"name\"]\n",
    "        playlist_features[\"album_name\"] = track[\"track\"][\"album\"][\"name\"]\n",
    "        playlist_features[\"song_name\"] = track[\"track\"][\"name\"]\n",
    "        playlist_features[\"song_id\"] = track[\"track\"][\"id\"]\n",
    "        \n",
    "        # Get audio features\n",
    "        audio_features = sp.audio_features(playlist_features[\"song_id\"])[0]\n",
    "        for feature in playlist_features_list[4:]:\n",
    "            playlist_features[feature] = audio_features[feature]\n",
    "        \n",
    "        # Concat the dfs\n",
    "        track_df = pd.DataFrame(playlist_features, index = [0])\n",
    "        playlist_df = pd.concat([playlist_df, track_df], ignore_index = True)\n",
    "        playlist_df[\"unique_identifier\"] = playlist_df[\"song_id\"]\n",
    "        playlist_df = playlist_df[[\"unique_identifier\", \"artist_name\",\"song_name\", \"song_id\",\"danceability\",\"energy\",\"key\",\"loudness\",\"mode\", \"speechiness\",\"instrumentalness\",\"liveness\",\"valence\",\"tempo\", \"duration_ms\",\"time_signature\"]]\n",
    "        playlist_df.to_csv(\"top50_songs_usa.csv\")\n",
    "        \n",
    "    # Step 3: Load into PostgreSQL\n",
    "    \n",
    "    engine = sqlalchemy.create_engine(f\"postgresql://{db_username}:{db_password}@localhost/spotify_etl\")\n",
    "    \n",
    "    playlist_df.to_sql(\"usa_top_50\",engine, index=False, if_exists=\"append\")\n",
    "\n",
    "spotify_top50usa_func(\"spotify\",\"37i9dQZEVXbLRQDuF5jeBp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2662b-735c-4351-9134-a9b4ba380937",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spotify_top50usa_func(\"spotify\",\"37i9dQZEVXbLRQDuF5jeBp\")\n",
    "except Exception as e:\n",
    "    print('Something broke...', e)\n",
    "finally:\n",
    "    engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9963cee5-cba7-4e88-b325-96dc2036d2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
